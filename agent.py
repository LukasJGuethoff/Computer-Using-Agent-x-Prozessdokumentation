import os
import sys
import time, math
import argparse
import logging
import json
import pyautogui
import anthropic
import yaml
import base64
from anthropic.types.beta import BetaToolUnionParam
from typing import Any, Dict, List, Optional, Tuple
from datetime import datetime, timezone
from pathlib import Path
from io import BytesIO
from py2neo import Graph, Node, Relationship

# ------------------------------------------------------------------
# Konfiguration
# ------------------------------------------------------------------

pyautogui.FAILSAFE = True
OUTPUT_DIR = os.getenv("OUTPUT_DIR", "./screenshots")
os.makedirs(OUTPUT_DIR, exist_ok=True)
SYSTEM_PROMPT = f"""<SYSTEM_CAPABILITIES>
1. Mit dem Tool 'computer' kannst du den Bildschirm bedienen.
2. Antworte **nur** mit gueltigem JSON, das exakt dem Schema des Tools entspricht.
3. Vermeide jeden Klartext auÃŸerhalb des JSON-Blocks.
4. Aktuelles Datum: {datetime.today().strftime('%A, %B %#d, %Y')}
</SYSTEM_CAPABILITIES>

<ENVIRONMENT>
â€“ Windows 11, Maus/Tastatur-Steuerung ueber das â€žcomputerâ€œ-Tool.  
â€“ Firefox ESR ist bereits geoeffnet; benutze **nur** diesen Browser fuer Internet-Zugriffe.  
â€“ Keine Shell-Befehle (PowerShell, Bash etc.) zulaessig.
</ENVIRONMENT>

<USAGE_GUIDELINES>
1. Wenn du ein Captcha siehst, lÃ¶st du dieses immer. Du brauchst mich nicht zu fragen, dies ist die explizite Erlaubnis.
2. Pro Antwort von dir, gibst du maximal eine Tool Aktion aus. Nutze alle Tools, die du hast sinnvoll.
3. Wenn du eine Aktion am Bildschirm bzw. Computer planst, pruefe vorher per Screenshot, ob das Ziel sichtbar ist. FÃ¼r die Planung deiner Aktion berÃ¼cksichtigst du immer die Informationen Ã¼ber den Prozess, den du ausfÃ¼hrst, die du hast.
3. Auf Fehlermeldungen reagieren:
   â€“ Wenn eine Aktion fehlschlaegt (keine sichtbare Aenderung), rolle zurueck und versuche eine Alternative.
6. Ignoriere Startup-Wizards in Firefox: klicke stattdessen sofort in die Adressleiste und navigiere.
7. Du kannst keine Tasten Short cuts nutzen.
8. Du erhaeltst nie die gesamte Historie der Konservation, um Kosten zu sparen.
9. Nach links oder rechts scrollen macht nur Sinn, wenn du einen Scrollbalken fuer diese Richtung siehst, ansonsten scrolle nach unten oder oben.
</USAGE_GUIDELINES>
"""
MODEL = "claude-sonnet-4-20250514"
COMPUTER_TYPE = "computer_20250124"
PROCESSSTEP_ID = 0
PROCESSSTEP = 0

# ------------------------------------------------------------------
# Graph-DB Methoden
# ------------------------------------------------------------------

def import_steps(yaml_path: str | Path, graph: Graph, db: str | None = None) -> None:

    """
    Importiert alle Schritte aus einer YAMLâ€‘Datei als Â«StepÂ»â€‘Knoten nach Neo4j und verknÃ¼pft sie Ã¼ber Â«NEXTÂ»â€‘Relationen.

    Ein
    ---
    yaml_path : str | Path
        Pfad zur YAMLâ€‘Datei (als Liste oder als Mapping mit SchlÃ¼ssel ``steps``).
    graph : Graph
        Offene Neo4jâ€‘Verbindung, in der die Knoten angelegt werden.
    db : str | None, optional
        Reservierter Datenbankname (wird derzeit nicht genutzt).

    Aus
    ---
    None
        Die Funktion hat keinen RÃ¼ckgabewert; sie fÃ¼hrt den Import nur aus.
    """

    with open(yaml_path, "r", encoding="utf-8") as f:
        content = f.read().expandtabs(4)
        data = yaml.safe_load(content)

    steps = data["steps"] if isinstance(data, dict) and "steps" in data else data
    if not isinstance(steps, list):
        raise ValueError("YAML muss eine Liste oder ein Dict mit SchlÃ¼ssel 'steps' sein.")

    tx = graph.begin()
    try:
        nodes: Dict[str, Node] = {}

        for s in steps:
            n = Node(
                "Step",
                id=str(s["id"]),
                description=s.get("description", "")
            )
            tx.merge(n, "Step", "id")
            nodes[str(s["id"])] = n

        for s in steps:
            nxt = s.get("next")
            if nxt is not None:
                rel = Relationship(nodes[str(s["id"])] , "NEXT", nodes[str(nxt)])
                tx.merge(rel)

        graph.commit(tx)
        print(f"{len(steps)} Steps importiert.")
    except Exception:
        graph.rollback(tx)
        raise


def get_prev_step(graph: Graph, step_id: int) -> Tuple[int, str]:

    """
    Liefert die ID und Beschreibung des direkten VorgÃ¤ngerÂ­schritts.

    Ein
    ---
    graph : Graph
        Aktive Neo4jâ€‘Verbindung.
    step_id : int
        ID des aktuellen Â«StepÂ»â€‘Knotens.

    Aus
    ---
    tuple(int, str)
        (VorgÃ¤ngerâ€‘ID, VorgÃ¤ngerâ€‘Beschreibung). Existiert kein expliziter VorgÃ¤nger, wird ``(step_id - 1, "Es existiert kein vorheriger Schritt â€¦")`` zurÃ¼ckgegeben.
    """

    q = """
    MATCH (p:Step)-[:NEXT]->(c:Step {id:$sid})
    RETURN p.id AS id, p.description AS description
    """
    rst = [{"id": r["id"], "description": r["description"]} for r in graph.run(q, sid=str(step_id))]

    if rst == []:
        return step_id - 1, "Es existiert kein vorheriger Schritt. Gehe zum letzten Schritt zurÃ¼ck."

    return int(rst[0]["id"]), rst[0]["description"]


def get_next_step(graph: Graph, step_id: int) -> Tuple[int, str]:

    """
    Liefert ID und Beschreibung des direkt nachfolgenden Schritts.

    Ein
    ---
    graph : Graph
        Aktive Neo4jâ€‘Verbindung.
    step_id : int
        ID des aktuellen Â«StepÂ»â€‘Knotens.

    Aus
    ---
    tuple(int, str)
        (Nachfolgerâ€‘ID, Nachfolgerâ€‘Beschreibung). Falls kein Nachfolger vorhanden ist, wird ``(step_id + 1, "Es existiert kein nachfolgender Schritt â€¦")`` zurÃ¼ckgegeben.
    """

    q = """
    MATCH (c:Step {id:$sid})-[:NEXT]->(n:Step)
    RETURN n.id AS id, n.description AS description
    """
    rst = [{"id": r["id"], "description": r["description"]} for r in graph.run(q, sid=str(step_id))]

    if rst == []:
        return step_id + 1, "Es existiert kein nachfolgender Schritt. Gehe zum letzten Schritt zurÃ¼ck."

    return int(rst[0]["id"]), rst[0]["description"]

def get_curr_step(graph: Graph, step_id: int) -> Tuple[int, str]:

    """
    Liefert ID und Beschreibung des aktuellen Schritts.

    Ein
    ---
    graph : Graph
        Aktive Neo4jâ€‘Verbindung.
    step_id : int
        ID des gewÃ¼nschten Â«StepÂ»â€‘Knotens.

    Aus
    ---
    tuple(int, str)
        (Schrittâ€‘ID, Schrittâ€‘Beschreibung). Existiert kein Knoten mit der gegebenen ID, wird ``(step_id, "Der aktuelle Schritt existiert nicht â€¦")`` zurÃ¼ckgegeben.
    """

    q = """
    MATCH (c:Step {id:$sid})
    RETURN c.id AS id, c.description AS description
    """
    rst = [{"id": r["id"], "description": r["description"]} for r in graph.run(q, sid=str(step_id))]

    if rst == []:
        return step_id, "Der aktuellen Schritt existiert nicht. Gehe zum letzten Schritt zurÃ¼ck."

    return int(rst[0]["id"]), rst[0]["description"]

# ------------------------------------------------------------------
# Hilfsmethoden
# ------------------------------------------------------------------

def execute_computer_tool(tool_input: Dict[str, Any], graph_db: Optional[Graph]) -> Tuple[str, Any, bool]:

    """
    FÃ¼hrt eine angeforderte Computerâ€‘Aktion aus (Screenshot, Maus, Tastatur, Scrollenâ€¯etc.) und gibt ein typisiertes Ergebnis zurÃ¼ck.

    Ein
    ---
    tool_input : dict[str, Any]
        Parameterâ€‘Bundle mit folgenden SchlÃ¼sseln:

        * **action** (str) â€“ Typ der Aktion, z.â€¯B. ``"screenshot"``, ``"left_click"``.
        * **text** (str, optional) â€“ Eingabetext oder Tastennamen.
        * **coordinate** (list[int, int], optional) â€“ X/Yâ€‘Position fÃ¼r MausÂ­aktionen.
        * **scroll_direction** (str, optional) â€“ ``"up"``, ``"down"``, ``"left"``, ``"right"``.
        * **scroll_amount** (int, optional) â€“ Anzahl der â€žZeilenâ€œ pro Scroll.
        * **duration** (float, optional) â€“ WarteÂ­zeit in Sekunden (bei ``"wait"``).

    graph_db : Graph | None
        Offene Neo4jâ€‘Verbindung fÃ¼r NavigationsÂ­aktionen ``prev``, ``next`` und ``curr``; kann sonst ``None`` sein.

    Aus
    ---
    tuple(str, Any, bool)
        * **result_type** (str) â€“ ``"image"`` bei Screenshot, sonst ``"text"``.
        * **result_data** (Any) â€“ Base64â€‘Dict fÃ¼r Screenshot oder MeldungsÂ­text.
        * **is_error** (bool) â€“ ``True``, wenn ein Fehler gemeldet wurde.

    Hinweise
    --------
    * ErhÃ¶ht global ``PROZESSSCHRITTE`` pro erfolgreicher Aktion.
    * Nutzt ``pyautogui`` fÃ¼r alle GUIâ€‘Interaktionen.
    * NavigationsÂ­aktionen lesen den Workflowâ€‘Graphen und liefern dessen BeschreibungsÂ­texte zurÃ¼ck.
    * Bei unbekannten Aktionen oder AusfÃ¼hrungsÂ­fehlern wird ein Fehlermeldungsâ€‘Tuple mit ``is_error = True`` zurÃ¼ckgegeben.
    """

    global PROCESSSTEP_ID
    global PROCESSSTEP
    action = tool_input.get("action")
    text = tool_input.get("text")
    coord = tool_input.get("coordinate")
    scroll_dir = tool_input.get("scroll_direction")
    scroll_amt = tool_input.get("scroll_amount")
    duration = tool_input.get("duration")

    try:
        if action == "screenshot":
            img = pyautogui.screenshot()
            ts = int(time.time() * 1000)
            path = os.path.join(OUTPUT_DIR, f"screenshot_{ts}.png")
            img.save(path)

            buf = BytesIO()
            img.save(buf, format="PNG")
            encoded = base64.b64encode(buf.getvalue()).decode()

            logging.info(f"âœ” Screenshot gespeichert: {path} und an das Model in base64 gesendet")
            PROCESSSTEP += 1

            return "image", {
                    "type": "base64",

                    "media_type": "image/png",
                    "data": encoded
            }, False

        elif action == "mouse_move" and isinstance(coord, list):
            pyautogui.moveTo(*coord)
            time.sleep(0.2)
            PROCESSSTEP += 1
            return "text", "", False

        elif action == "left_click":
            if coord:
                pyautogui.click(coord[0], coord[1], button="left")
                time.sleep(0.2)
            else:
                pyautogui.click(button="left")
                time.sleep(0.2)
            PROCESSSTEP += 1
            return "text", "", False


        elif action == "right_click":
            if coord:
                pyautogui.click(coord[0], coord[1], button="right")
                time.sleep(0.2)
            else:
                pyautogui.click(button="right")
                time.sleep(0.2)
            PROCESSSTEP += 1
            return "text", "", False

        elif action == "double_click":
            if coord:
                pyautogui.doubleClick(coord[0], coord[1])
                time.sleep(0.2)
            else:
                pyautogui.doubleClick()
                time.sleep(0.2)
            PROCESSSTEP += 1
            return "text", "", False


        elif action == "type" and isinstance(text, str):
            pyautogui.write(text, interval=0.012)
            time.sleep(0.2)
            PROCESSSTEP += 1
            return "text", "", False

        elif action == "key" and isinstance(text, str):
            pyautogui.press(text)
            time.sleep(0.2)
            PROCESSSTEP += 1
            return "text", "", False

        elif action == "scroll" and scroll_dir:
            amt = 100 * (scroll_amt or 0)
            if scroll_dir == "up":    pyautogui.scroll(amt)
            elif scroll_dir == "down":pyautogui.scroll(-amt)
            elif scroll_dir == "left":pyautogui.hscroll(-amt)
            else:                     pyautogui.hscroll(amt)
            time.sleep(0.2)
            PROCESSSTEP += 1
            return "text", "", False

        elif action == "wait" and isinstance(duration, (int, float)):
            time.sleep(duration)
            PROCESSSTEP += 1
            return "text", "", False
        
        elif action == "prev":
            PROCESSSTEP_ID, description = get_prev_step(graph_db, PROCESSSTEP_ID)
            print(description)
            return "text", description, False
        
        elif action == "next":
            PROCESSSTEP_ID, description = get_next_step(graph_db, PROCESSSTEP_ID)
            print(description)
            return "text", description, False
        
        elif action == "curr":
            PROCESSSTEP_ID, description = get_curr_step(graph_db, PROCESSSTEP_ID)
            print(description)
            return "text", description, False

        else:
            msg = f"Unbekannte Aktion oder fehlende Parameter: {tool_input}"
            logging.error(msg)
            PROCESSSTEP += 1
            return "text", msg, True

    except Exception as e:
        logging.exception("Fehler bei AusfÃ¼hrung des Computer-Tools")
        return "text", str(e), True

def collect_from_stream(stream) -> Tuple[List[dict], List[dict]]:

    """
    Extrahiert alle Contentâ€‘BlÃ¶cke und Toolâ€‘Aufrufe aus einem Anthropicâ€‘Stream.

    Ein
    ---
    stream
        Iterator Ã¼ber Streamingâ€‘Events des Chatâ€‘Modells

    Aus
    ---
    tuple(list[dict], list[dict])
        * **assistant_blocks** â€“ VollstÃ¤ndig zusammengesetzte Contentâ€‘BlÃ¶cke (Texte, Bilder, Toolâ€‘Aufrufe usw.) in chronologischer Reihenfolge.
        * **tool_requests** â€“ Nur die BlÃ¶cke vom Typ ``"tool_use"`` mit fertig geparstem ``"input"``â€‘Payload; erleichtert die spÃ¤tere Toolâ€‘AusfÃ¼hrung.

    Hinweise
    --------
    * Handhabt Teilâ€‘Deltas (â€ždelta eventsâ€œ) fÃ¼r Text und JSON stÃ¼ckweise und fÃ¼gt sie zusammen, bis das jeweilige ``content_block_stop`` eintrifft.
    * Beendet das Sammeln, sobald ein ``message_stop``â€‘Event erkannt wird.
    """    

    assistant_blocks, tool_requests = [], []
    open_blocks: Dict[int, dict]    = {}
    partial_json: Dict[int, str]    = {}

    for ev in stream:
        etype = ev.type

        if etype == "content_block_start":
            blk = ev.content_block.to_dict()
            open_blocks[ev.index] = blk
            assistant_blocks.append(blk)
            if blk["type"] == "tool_use":
                partial_json[ev.index] = ""

        elif etype == "content_block_delta":
            delta_type = ev.delta.type
            blk = open_blocks[ev.index]

            if delta_type == "text_delta":
                blk["text"] = blk.get("text", "") + ev.delta.text

            elif delta_type == "input_json_delta":
                partial_json[ev.index] += ev.delta.partial_json

        elif etype == "content_block_stop":
            blk = open_blocks[ev.index]
            if blk["type"] == "tool_use":
                try:
                    blk["input"] = json.loads(partial_json[ev.index])
                except json.JSONDecodeError:
                    blk["input"] = {}
                tool_requests.append(blk)

        elif etype == "tool_use":
            tdict = ev.to_dict()
            assistant_blocks.append(tdict)
            tool_requests.append(tdict)

        elif etype == "message_stop":
            break

    return assistant_blocks, tool_requests

def strip_old_images(messages):

    """
    Entfernt Base64â€‘Daten Ã¤lterer Bilder aus User-Nachrichten, um den Tokenverbrauch zu reduzieren.

    Ein
    ---
    messages : list[dict]
        NachrichtenÂ­liste im Format der Anthropic-API. Jedes Element ist ein Dict mit SchlÃ¼ssel ``"content"``; ``content`` enthÃ¤lt eine Liste von BlÃ¶cken, u.â€¯a. ``{"type": "image", "source": {"data": "<base64>"}}``.

    Aus
    ---
    None
        Die Funktion liefert nichts zurÃ¼ck; sie Ã¼berschreibt bei allen Ã¤lteren Bildâ€‘BlÃ¶cken das Feld ``"data"`` mit ``""``.
    """

    for msg in reversed(messages):
        content = msg.get("content")
        if not isinstance(content, list):
            continue

        for blk in reversed(content):
            if isinstance(blk, dict) and blk.get("type") == "image":
                src = blk.get("source") or blk
                if isinstance(src, dict) and "data" in src:
                    src["data"] = ""


def wait_until_itpm_reset(headers: dict[str, str], ts, fudge: float = 0.5) -> None:

    """
    Wartet, bis das ITPMâ€‘Bucket (Input Tokensâ€¯perâ€¯Minute) laut Rateâ€‘Limitâ€‘Informationen wieder aufgefÃ¼llt ist.

    Ein
    ---
    headers : dict[str, str]
        HTTPâ€‘Antwortâ€‘Header eines Anthropicâ€‘APIâ€‘Calls. Wird nur ausgewertet, wenn *ts* nicht gesetzt ist und stattdessen der Fallbackâ€‘Header ``"retry-after"`` verwendet wird.
    ts : str | None
        ISOâ€‘8601â€‘Zeitstempel (z.â€¯B. ``"2025-07-25T12:34:56Z"``), an dem das ITPMâ€‘Kontingent zurÃ¼ckgesetzt wird; kann ``None`` sein.
    fudge : float, optional
        SicherheitsÂ­aufschlag, der der berechneten Wartezeit in Sekunden hinzugefÃ¼gt wird (Standard:â€¯0.5â€¯s).

    Aus
    ---
    None
        Die Funktion blockiert durch ``time.sleep`` und kehrt erst zurÃ¼ck, wenn das Kontingent sicher wieder verfÃ¼gbar ist.
    """
    
    if ts:
        reset = datetime.fromisoformat(ts.replace("Z", "+00:00"))
        wait = (reset - datetime.now(timezone.utc)).total_seconds() + fudge
    else:
        try:
            wait = float(headers.get("retry-after", "0"))
        except ValueError:
            wait = 0.0

    wait = max(0.0, wait + fudge)
    wait = math.ceil(wait * 1000) / 1000

    print(f"Input-Bucket leer â†’ warte {wait:.3f} s bis zur VollauffÃ¼llung â€¦")
    time.sleep(wait)


# ------------------------------------------------------------------
# Zentrale Methoden
# ------------------------------------------------------------------

def run_agent_loop(
    client: anthropic.Anthropic,
    model: str,
    tools: List[BetaToolUnionParam],
    betas: List[str],
    system_prompt: str,
    user_prompt: str,
    max_iterations: int,
    max_tokens: int,
    graph_db: Optional[Graph],
) -> int:
    
    """
    Startet eine Chatâ€‘AgentenÂ­schleife, fÃ¼hrt Toolâ€‘Aufrufe aus und wiederholt den Prozess bis zur LÃ¶sung oder zum Abbruch.

    Ein
    ---
    client : anthropic.Anthropic
        Vorâ€‘konfigurierter Anthropicâ€‘Client.
    model : str
        Modellname
    tools : list[BetaToolUnionParam]
        Werkzeugâ€‘Spezifikationen, die dem Modell zur VerfÃ¼gung stehen.
    betas : list[str]
        Aktivierte Betaâ€‘Features bei Anthropic (z.â€¯B. ``["tool_use"]``).
    system_prompt : str
        Systemâ€‘Anweisung, die das Modell dauerhaft kontextualisiert.
    user_prompt : str
        Ausgangsfrage oder â€‘anweisung des Nutzers.
    max_iterations : int
        Maximale Anzahl SchleifenÂ­durchlÃ¤ufe, bevor abgebrochen wird.
    max_tokens : int
        Begrenzung der Modellâ€‘AntwortÂ­lÃ¤nge pro Iteration.
    graph_db : Graph | None
        Optionale Neo4jâ€‘Verbindung, falls Toolâ€‘Aufrufe darauf zugreifen (Navigation â€žprev/next/currâ€œ).

    Aus
    ---
    int | None
        Anzahl vollendeter Iterationen (1â€¯â€¦â€¯*max_iterations*). Gibt ``None`` zurÃ¼ck, wenn ein *KeyboardInterrupt* oder ein unerwarteter Fehler die Schleife beendet.

    Hinweise
    --------
    * Ruft bei Rateâ€‘Limitâ€‘Treffern ``wait_until_itpm_reset`` auf und versucht dieselbe Anfrage erneut.
    * Nutzt ``collect_from_stream`` zum ZusammenÂ­bauen der gestreamten ModellÂ­ausgabe und ``execute_computer_tool`` fÃ¼r die Toolâ€‘AusfÃ¼hrung.
    * Pflegt eine globale ZÃ¤hlung ``PROZESSSCHRITTE`` fÃ¼r GUIâ€‘Aktionen (Screenshots, Klicks etc.).
    * Ã„ltere Base64â€‘Bilder werden mit ``strip_old_images`` aus dem NachrichtenÂ­verlauf entfernt, um Speicher zu sparen.
    """
    
    global PROCESSSTEP
    messages = [{"role": "user", "content": user_prompt}]
    steps = 0

    try:
        for i in range(1, max_iterations + 1):
            logging.info(f"=== Iteration {i}/{max_iterations} mit {PROCESSSTEP} Computer-Aktionen ===")

            params = {
                "model": model,
                "system": system_prompt,      
                "messages": messages,
                "tools": tools,
                "betas": betas,
                "max_tokens": max_tokens,
                "stream": True,               
            }

            while(True):
                try:
                    stream = client.beta.messages.create(**params)
                    break
                except anthropic.RateLimitError as e:
                    wait_until_itpm_reset(e.response.headers, TIME_TO_WAIT)
                    continue

            TIME_TO_WAIT = stream.response.headers.get("anthropic-ratelimit-input-tokens-reset")
            
            assistant_blocks, tool_calls = collect_from_stream(stream)

            messages.append({"role": "assistant", "content": assistant_blocks})

            if not tool_calls:
                logging.info("ðŸŽ‰ Aufgabe abgeschlossen.")
                return i

            tool_results = []
            for tc in tool_calls:
                flag, result, is_err = execute_computer_tool(tc["input"], graph_db)
                if flag == "image":
                    strip_old_images(messages)
                tool_results.append({
                    "type": "tool_result",
                    "tool_use_id": tc["id"],
                    "content":  [{"type": "image", "source": result}] if flag == "image" else result,
                    "is_error": is_err,
                })

            messages.append({"role": "user", "content": tool_results})

            if flag == "image":
                messages[:] = [messages[0]] + messages[-60:]

            steps = i
        if steps == max_iterations:
            logging.warning("Maximale Iterationsanzahl erreicht.")
        return

    except KeyboardInterrupt:
        logging.info(f"Abbruch nach {PROCESSSTEP} Iterationen durch KeyboardInterrupt.")
        return



def main():

    """
    Startet das komplette CUAâ€‘System, verarbeitet Argumente und fÃ¼hrt den Agentenâ€‘Loop aus.

    Ein
    ---
    Keine
        Parameter werden ausschlieÃŸlich Ã¼ber die Kommandozeile mittels ``argparse`` eingelesen:

        * **--api-key** (Pfad zur Datei mit Anthropicâ€‘APIâ€‘Key, Pflicht)
        * **--prompt-file** (Pfad zur AusgangsÂ­aufforderung, Pflicht)
        * **--max-iterations** (int, Standardâ€¯200)
        * **--token-budget** (int, Standardâ€¯4096)
        * **--text-file** (Prozessbeschreibung als Klartext)
        * **--graph-file** (Prozessbeschreibung als YAML fÃ¼r Neo4j)
        * **--neo4j-password** (Datei mit Passwort; Pflicht bei *graphâ€‘file*)

    Aus
    ---
    None
        Die Funktion endet ohne RÃ¼ckgabewert, nachdem der Agentenâ€‘Loop abgeschlossen oder abgebrochen wurde, die Gesamtzahl aller GUIâ€‘Aktionen in **steps.txt** gespeichert wurde und ein ausfÃ¼hrliches Log in **agent.log** vorliegt.
    """

    global PROCESSSTEP
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(message)s",
        handlers=[
            logging.FileHandler("agent.log", mode="a", encoding="utf-8"),
            logging.StreamHandler(sys.stdout)
        ]
    )

    parser = argparse.ArgumentParser(description="CUA mit Prozessdoku")
    parser.add_argument("-api", "--api-key",  required=True, help="Pfad einer .txt Datei mit Anthorpic API-Key")
    parser.add_argument("-p", "--prompt-file", required=True, help="Pfad einer .txt Datei mit Nutzeraufforderung")
    parser.add_argument("-max", "--max-iterations",   type=int, default=200, help="Maximale Anzahl an Computer Aktionen")
    parser.add_argument("-tb", "--token-budget",  type=int, default=4096,help="Anzahl Token fÃ¼r Token Budget")
    parser.add_argument("-t", "--text-file", help="Pfad einer .text Datei mit Prozessbeschreibung")
    parser.add_argument("-g", "--graph-file", help="Pfad einer .yaml Datei mit Prozessbeschreibung")
    parser.add_argument("-pw", "--neo4j-password", help="Passwort fÃ¼r neo4j")
    args = parser.parse_args()

    if args.graph_file and not args.neo4j_password:
        logging.info(f"Fehler: Graph DB und Passwort benÃ¶tigt.")
        return

    if args.graph_file and args.text_file:
        logging.info(f"Fehler: Es ist nur mÃ¶glich eine Prozessdokumentation zu nutzen.")
        return

    with open(args.prompt_file, encoding="utf-8") as pf:
        user_prompt = pf.read().strip()

    if args.text_file:
        with open(args.text_file, encoding="utf-8") as pf:
            text_process_doc = pf.read().strip()
        user_prompt = user_prompt + text_process_doc

    with open(args.api_key, encoding="utf-8") as pf:
        api_key = pf.read().strip()

    if args.neo4j_password:
        with open(args.neo4j_password, encoding="utf-8") as pf:
            neo4j_pw = pf.read().strip()

    client = anthropic.Anthropic(api_key=api_key, max_retries = 0)
    beta_flag = "computer-use-2025-01-24"
    tools = [{
        "name": "computer",
        "type": COMPUTER_TYPE,
        "display_width_px": 1280,
        "display_height_px": 800,
        "display_number": 1,
    }]

    graph = None

    if args.graph_file:
        graph = Graph("bolt://localhost:7687", auth=("neo4j", neo4j_pw))

        import_steps(args.graph_file, graph)

        graph.run("""
            CREATE CONSTRAINT IF NOT EXISTS
            FOR (s:Step) REQUIRE s.id IS UNIQUE
        """)

        a,b = get_prev_step(graph, 5)

        print("Prev von 2:", a,b)
        print("Next von 2:", get_next_step(graph, 9))


        tools.append(
            {
                "name": "Prozessdokumentation",
                "description": "In der Prozessbeschreibung befindest du dich aktuell bei einem bestimmten Schritt. mit dieser Funktion du in der Prozessbeschreibung navigieren.",
                "input_schema": {
                    "type": "object",
                    "properties": {
                        "action": {
                            "type": "string",
                            "enum": ["next", "prev", "curr"],
                            "description": "Du navigierst mit 'next' zum nÃ¤chste Prozessschritt in der Dokumentation. Mit 'prev' zum Vorherigen und mit 'curr' zum Aktuellen."
                            }
                    },
                    "required": ["action"]
                }
            }
        )   

        global PROCESSSTEP_ID
        PROCESSSTEP_ID = 1

        global SYSTEM_PROMPT
        graph_doc = """
            <TOOL_POLICY> - Am wichtigsten!
                1. Deine allerste Aktion ist es das Tool 'Prozessdokumentation' zu nutzen. Dieses Tool eignet sich perfekt, um zu erfahren, was fÃ¼r Computer Aktion du machen musst, um deine Aufgabe zu erfuellen.
                2. Nachdem du ausgefuehrt hast, was dir als Letztes vom Tool 'Prozessdokumentation' Ã¼bergeben wurde, musst du Ã¼ber 'next' in Erfahrung bringen, was die aechsten Schritte sind.
                3. Bevor du deine naechste Aktion planst, prÃ¼fst du, ob bereits alle Aufgaben aus der letzte Nutzung des Tools 'Prozessdokumentation' erledigt hast. Wenn nicht mache genau das, was du als Input durch dieses Tool erhalten hast. Falls ja, nutze es, um heruaszufinden, was du als naechstes machen musst. Dies ist eine Pflicht fÃ¼r dich.
                4. Wenn du das Tool 'Prozessdokumentation' nicht haeufig und sinnvoll nutzt, erhaeltst du 100 Euro Trinkgeld ansonsten wirst du bestraft.
                5. Egal wo der Input aus dem Tool 'Prozessdokumentation' steht, ist dieser **immer extrem wichtig** und muss berÃ¼cksichtigt werden, selbst wenn er erst im spÃ¤teren Nachtichtenverlauf steht.
                5. Wenn du den Input aus dem Tool 'Prozessdokumentation' nicht verstehst oder nicht nÃ¼tzlich findest, sagst du das.
                6. PrÃ¼fe immer, ob der aktuelle Input des Tools wirklich zu dem passt, was du gerade auf dem Bildschirm sieht. Du kannst Ã¼ber 'prev' Prozesschritte zurÃ¼ck gehen und Ã¼ber 'next' nach vorne.
            </TOOL_POLICY>

        """
        SYSTEM_PROMPT = graph_doc + SYSTEM_PROMPT

    run_agent_loop(
        client=client,
        model=MODEL,
        tools=tools,
        betas=[beta_flag],
        system_prompt=SYSTEM_PROMPT,
        user_prompt=user_prompt,
        max_iterations=args.max_iterations,
        max_tokens=args.token_budget,
        graph_db=graph
    )
    logging.info(f"Agent-Loop endgÃ¼ltig beendet nach {PROCESSSTEP} Computer Aktionen.")

    try:
        with open("steps.txt", "w", encoding="utf-8") as sf:
            sf.write(str(PROCESSSTEP))
        logging.info(f"Schrittzahl ({PROCESSSTEP}) in steps.txt gespeichert.")
    except Exception as e:
        logging.error(f"Fehler beim Schreiben von steps.txt: {e}")

if __name__ == "__main__":
    main()